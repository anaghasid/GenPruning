{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216,"modelId":3301}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-16T14:59:30.652274Z","iopub.execute_input":"2024-10-16T14:59:30.653259Z","iopub.status.idle":"2024-10-16T14:59:30.662440Z","shell.execute_reply.started":"2024-10-16T14:59:30.653205Z","shell.execute_reply":"2024-10-16T14:59:30.661512Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/gemma/transformers/2b/2/model.safetensors.index.json\n/kaggle/input/gemma/transformers/2b/2/gemma-2b.gguf\n/kaggle/input/gemma/transformers/2b/2/config.json\n/kaggle/input/gemma/transformers/2b/2/model-00001-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/model-00002-of-00002.safetensors\n/kaggle/input/gemma/transformers/2b/2/tokenizer.json\n/kaggle/input/gemma/transformers/2b/2/tokenizer_config.json\n/kaggle/input/gemma/transformers/2b/2/special_tokens_map.json\n/kaggle/input/gemma/transformers/2b/2/.gitattributes\n/kaggle/input/gemma/transformers/2b/2/tokenizer.model\n/kaggle/input/gemma/transformers/2b/2/generation_config.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install bert-score\n# !pip install rouge-score\n# from nltk.translate.bleu_score import sentence_bleu\n# from rouge_score import rouge_scorer\nimport nltk\n# from transformers.modeling_utils import prune_linear_layer\nfrom collections import defaultdict\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom torch.utils.data.dataset import Dataset\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-10-16T14:59:30.663985Z","iopub.execute_input":"2024-10-16T14:59:30.664321Z","iopub.status.idle":"2024-10-16T14:59:32.828490Z","shell.execute_reply.started":"2024-10-16T14:59:30.664288Z","shell.execute_reply":"2024-10-16T14:59:32.827687Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class IndexDataset(Dataset):\n    def __init__(self, tensors):\n        self.tensors = tensors\n\n    def __getitem__(self, index):\n        return self.tensors[index]\n\n    def __len__(self):\n        return len(self.tensors)\n\ndef process_data(samples, tokenizer, seq_len, field_name):\n    test_ids = tokenizer(\"\\n\\n\".join(samples[field_name]), return_tensors='pt').input_ids[0]\n    test_ids_batch = []\n    nsamples = test_ids.numel() // seq_len\n\n    for i in range(nsamples):\n        batch = test_ids[(i * seq_len):((i + 1) * seq_len)]\n        test_ids_batch.append(batch)\n    test_ids_batch = torch.stack(test_ids_batch)\n    return IndexDataset(tensors=test_ids_batch)\n       \n\ndef get_loaders(tokenizer, seq_len=2048, batch_size = 8):\n    test_data = load_dataset('wikitext', 'wikitext-2-raw-v1', split='test')\n#     test_dataset = process_data(test_data, tokenizer, seq_len, 'text')\n    test_dataset = process_data(test_data[0:100], tokenizer, seq_len, 'text')\n\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n    return test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def PPLMetric(model, tokenizer, seq_len=128, batch_size = 4, device=\"cuda\"):\n    metric = {}\n    test_loader = get_loaders(tokenizer, seq_len=seq_len, batch_size = batch_size)\n    metric = ppl_eval(model, test_loader, device)\n    print(metric)\n    return metric\n\n\ndef ppl_eval(model, test_lodaer, device):\n    nlls = []\n    n_samples = 0\n    with torch.no_grad():\n        for batch in tqdm(test_lodaer):\n            batch = batch.to(device)\n            # CHANGE THIS:\n            output = model(batch)\n            lm_logits = output.logits\n\n            shift_logits = lm_logits[:, :-1, :].contiguous()\n            shift_labels = batch[:, 1:].contiguous()\n\n            loss_fct = torch.nn.CrossEntropyLoss(reduction=\"none\")\n            loss = loss_fct(shift_logits.reshape(-1, shift_logits.size(-1)), shift_labels.view(-1))\n            nlls.append(loss)\n            del batch\n            for _ in range(10):\n                torch.cuda.empty_cache()\n                gc.collect()\n    #print(torch.cat(nlls, dim=-1).mean())\n    ppl = np.exp(torch.cat(nlls, dim=-1).mean().item())\n    return ppl.item()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:16:53.314045Z","iopub.execute_input":"2024-10-16T15:16:53.315108Z","iopub.status.idle":"2024-10-16T15:16:53.324562Z","shell.execute_reply.started":"2024-10-16T15:16:53.315061Z","shell.execute_reply":"2024-10-16T15:16:53.323515Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def make_model():\n    try:\n        del model\n        print(\"Deleted existing\")\n        for _ in range(10):\n            torch.cuda.empty_cache()\n            gc.collect()\n    except:\n        pass\n    model = GemmaForCausalLM.from_pretrained(model_name)  # Use the appropriate model class\n    model.to(device)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:22:36.518749Z","iopub.execute_input":"2024-10-16T15:22:36.519643Z","iopub.status.idle":"2024-10-16T15:22:36.598656Z","shell.execute_reply.started":"2024-10-16T15:22:36.519592Z","shell.execute_reply":"2024-10-16T15:22:36.597514Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, AutoModel, GemmaForCausalLM \nimport torch\nmodel_name = '/kaggle/input/gemma/transformers/2b/2'  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = make_model()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:17.507493Z","iopub.execute_input":"2024-10-16T15:04:17.507884Z","iopub.status.idle":"2024-10-16T15:04:50.477890Z","shell.execute_reply.started":"2024-10-16T15:04:17.507845Z","shell.execute_reply":"2024-10-16T15:04:50.477032Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2405822039a94f5b92e6dcc5c69154d7"}},"metadata":{}}]},{"cell_type":"code","source":"import random\ndef create_random_binary_list(length, percentage_of_zeros):\n    num_zeros = int(length * percentage_of_zeros)\n    num_ones = length - num_zeros\n\n    # Create the list with the required number of 0s and 1s\n    binary_list = [0] * num_zeros + [1] * num_ones\n\n    # Shuffle the list to randomize the order\n    random.shuffle(binary_list)\n\n    return binary_list\n\ndef initialize_chromosome(num_genes):\n  # initialize chromosome with given sparsity percentage\n  return create_random_binary_list(num_genes, SPARSITY_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:50.479695Z","iopub.execute_input":"2024-10-16T15:04:50.480026Z","iopub.status.idle":"2024-10-16T15:04:50.485836Z","shell.execute_reply.started":"2024-10-16T15:04:50.479976Z","shell.execute_reply":"2024-10-16T15:04:50.484775Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def modify_model(model, chromosome):\n    num_heads = model.config.num_attention_heads\n    num_blocks = model.config.num_hidden_layers\n    # num_ffn = model.config.num_hidden_layers\n\n    # Disable attention heads\n    heads_to_prune = defaultdict(list)\n    for i, gene in enumerate(chromosome):\n        if gene == 0:\n          block_num = i//num_heads\n          head_num = i%num_heads\n          heads_to_prune[block_num].append(head_num)\n\n    head_dim = model.config.head_dim\n    if heads_to_prune:\n        print(\"Pruning heads in model\")\n        with torch.no_grad():\n            for block in range(block_num): \n                for head in heads_to_prune[block]:\n                        # Zero-out the corresponding rows in the q_proj, k_proj, and v_proj\n                        start_index = head * head_dim\n                        end_index = (head + 1) * head_dim\n                        model.model.layers[block].self_attn.q_proj.weight[start_index:end_index, :] = 0\n                        model.model.layers[block].self_attn.k_proj.weight[start_index:end_index, :] = 0\n                        model.model.layers[block].self_attn.v_proj.weight[start_index:end_index, :] = 0\n\n    #                     model.model.layers[block_num].self_attn.q_proj.weight = model.model.layers[block_num].self_attn.q_proj.weight.to(torch.int8)\n    #                     model.model.layers[block_num].self_attn.k_proj.weight = model.model.layers[block_num].self_attn.q_proj.weight.to(torch.int8)\n    #                     model.model.layers[block_num].self_attn.c_proj.weight = model.model.layers[block_num].self_attn.q_proj.weight.to(torch.int8)\n\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:50.487069Z","iopub.execute_input":"2024-10-16T15:04:50.487426Z","iopub.status.idle":"2024-10-16T15:04:50.503716Z","shell.execute_reply.started":"2024-10-16T15:04:50.487376Z","shell.execute_reply":"2024-10-16T15:04:50.502882Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def evaluate_fitness(chromosome):\n    model = make_model()\n    model = modify_model(model,chromosome)\n    metric = PPLMetric(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:19:22.696285Z","iopub.execute_input":"2024-10-16T15:19:22.697257Z","iopub.status.idle":"2024-10-16T15:19:22.702032Z","shell.execute_reply.started":"2024-10-16T15:19:22.697208Z","shell.execute_reply":"2024-10-16T15:19:22.701059Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"SPARSITY_RATE = 0.3","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:50.519422Z","iopub.execute_input":"2024-10-16T15:04:50.519824Z","iopub.status.idle":"2024-10-16T15:04:50.527818Z","shell.execute_reply.started":"2024-10-16T15:04:50.519781Z","shell.execute_reply":"2024-10-16T15:04:50.527048Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def find_size(model):\n  total_size_in_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n  total_size_in_megabytes = total_size_in_bytes / (1024 ** 2)\n  print(f\"Model size: {total_size_in_megabytes:.2f} MB\")","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:50.528823Z","iopub.execute_input":"2024-10-16T15:04:50.529130Z","iopub.status.idle":"2024-10-16T15:04:50.538608Z","shell.execute_reply.started":"2024-10-16T15:04:50.529099Z","shell.execute_reply":"2024-10-16T15:04:50.537811Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# model = make_model()\nmetric = PPLMetric(model, tokenizer)\nfind_size(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:06:29.514982Z","iopub.execute_input":"2024-10-16T15:06:29.515408Z","iopub.status.idle":"2024-10-16T15:09:57.008607Z","shell.execute_reply.started":"2024-10-16T15:06:29.515370Z","shell.execute_reply":"2024-10-16T15:09:57.007672Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 564/564 [03:24<00:00,  2.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"648.7878413946279\nModel size: 9560.29 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"chrom = initialize_chromosome(model.config.num_attention_heads*model.config.num_hidden_layers)\n# model = modify_model(model, chrom)\n# find_size(model)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:26.646191Z","iopub.execute_input":"2024-10-16T15:11:26.647325Z","iopub.status.idle":"2024-10-16T15:11:26.652316Z","shell.execute_reply.started":"2024-10-16T15:11:26.647279Z","shell.execute_reply":"2024-10-16T15:11:26.651083Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:04:57.795287Z","iopub.status.idle":"2024-10-16T15:04:57.795781Z","shell.execute_reply.started":"2024-10-16T15:04:57.795524Z","shell.execute_reply":"2024-10-16T15:04:57.795550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"POPN_SIZE = 8\ncrossover_rate = 0.7\nmutation_rate = 0.08\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.023888Z","iopub.execute_input":"2024-10-16T15:11:57.024848Z","iopub.status.idle":"2024-10-16T15:11:57.030211Z","shell.execute_reply.started":"2024-10-16T15:11:57.024792Z","shell.execute_reply":"2024-10-16T15:11:57.028934Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def initialize_population(chromosome_length):\n  # initialize random population\n  population = []\n  for _ in range(POPN_SIZE):\n    chromosome = initialize_chromosome(chromosome_length)\n    population.append(chromosome)\n  return population","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.032343Z","iopub.execute_input":"2024-10-16T15:11:57.032709Z","iopub.status.idle":"2024-10-16T15:11:57.043520Z","shell.execute_reply.started":"2024-10-16T15:11:57.032668Z","shell.execute_reply":"2024-10-16T15:11:57.042568Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def select_parents(population, fitness_scores, num_parents):\n    # Normalize fitness scores to create a probability distribution\n    total_fitness = np.sum(fitness_scores)\n    probabilities = fitness_scores / total_fitness\n\n    # Select parents based on their fitness proportion (roulette wheel selection)\n    # selected_parents = np.random.choice(population, size=num_parents, p=probabilities, replace=True)\n    selected_parents = random.choices(population, weights=probabilities, k=num_parents)\n\n\n    return np.array(selected_parents)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.044573Z","iopub.execute_input":"2024-10-16T15:11:57.044862Z","iopub.status.idle":"2024-10-16T15:11:57.063533Z","shell.execute_reply.started":"2024-10-16T15:11:57.044831Z","shell.execute_reply":"2024-10-16T15:11:57.062663Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Crossover (Single-point crossover)\ndef crossover(parent1, parent2):\n    if np.random.rand() < crossover_rate:\n        point = np.random.randint(1, len(parent1) - 1)\n        child1 = np.concatenate([parent1[:point], parent2[point:]])\n        child2 = np.concatenate([parent2[:point], parent1[point:]])\n    else:\n        child1, child2 = parent1, parent2\n    return child1, child2","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.064954Z","iopub.execute_input":"2024-10-16T15:11:57.065321Z","iopub.status.idle":"2024-10-16T15:11:57.078573Z","shell.execute_reply.started":"2024-10-16T15:11:57.065278Z","shell.execute_reply":"2024-10-16T15:11:57.077730Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Mutation (Flip bit mutation)\ndef mutate(chromosome):\n    for i in range(len(chromosome)):\n        if np.random.rand() < mutation_rate:\n            chromosome[i] = 1 - chromosome[i]\n\n    target_zeros = int(len(chromosome) * SPARSITY_RATE)\n\n    for c in range(model.config.num_attention_heads-1, len(chromosome), model.config.num_attention_heads):\n      # this part to ensure that each layer has at least one attention head\n      start = c-model.config.num_attention_heads-1\n      enc_part = chromosome[start:c]\n      num_ones = np.sum(enc_part)  # Count the number of 1s in the chromosome\n      if num_ones==0:\n        chromosome[start] = 1\n\n    for i in range(len(chromosome)):\n        if np.random.rand() < mutation_rate:\n            if chromosome[i] == 1 and num_ones > target_ones:\n                chromosome[i] = 0  # Flip 1 to 0 only if there are too many 1s\n                num_ones -= 1\n            elif chromosome[i] == 0 and num_ones < target_ones:\n                chromosome[i] = 1  # Flip 0 to 1 only if there are too few 1s\n                num_ones += 1\n    return chromosome\n","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.081333Z","iopub.execute_input":"2024-10-16T15:11:57.081704Z","iopub.status.idle":"2024-10-16T15:11:57.091579Z","shell.execute_reply.started":"2024-10-16T15:11:57.081663Z","shell.execute_reply":"2024-10-16T15:11:57.090458Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def elitism_and_selection(population, fitness_scores, num_elites, num_parents):\n    # Elitism: Keep the top num_elites individuals\n    elite_indices = np.argsort(fitness_scores)[-num_elites:]  # Get indices of top individuals\n    elites = [population[i] for i in elite_indices]\n\n    # Perform roulette wheel selection for the rest of the parents\n    remaining_population = np.delete(population, elite_indices, axis=0)\n    remaining_fitness_scores = np.delete(fitness_scores, elite_indices)\n\n    num_to_select = num_parents - num_elites\n    selected_parents = select_parents(remaining_population, remaining_fitness_scores, num_to_select)\n\n    # Combine elites and selected parents\n    next_generation = np.vstack((elites, selected_parents))\n\n    return next_generation","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:11:57.092888Z","iopub.execute_input":"2024-10-16T15:11:57.093270Z","iopub.status.idle":"2024-10-16T15:11:57.102629Z","shell.execute_reply.started":"2024-10-16T15:11:57.093228Z","shell.execute_reply":"2024-10-16T15:11:57.101734Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = make_model()","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:18:38.131666Z","iopub.execute_input":"2024-10-16T15:18:38.132572Z","iopub.status.idle":"2024-10-16T15:18:44.901324Z","shell.execute_reply.started":"2024-10-16T15:18:38.132527Z","shell.execute_reply":"2024-10-16T15:18:44.900255Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a71d438c1f704664aedf78abf5790b4f"}},"metadata":{}}]},{"cell_type":"code","source":"num_attention_heads = model.config.num_attention_heads\nnum_hidden_layers = model.config.num_hidden_layers","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:18:48.485481Z","iopub.execute_input":"2024-10-16T15:18:48.485913Z","iopub.status.idle":"2024-10-16T15:18:48.490943Z","shell.execute_reply.started":"2024-10-16T15:18:48.485873Z","shell.execute_reply":"2024-10-16T15:18:48.489728Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef genetic_algorithm(num_generations, desired_sparsity):\n  population = initialize_population(num_attention_heads*num_hidden_layers)  # Initialize the population\n  accuracy_per_generation = []  # List to store highest accuracy values for each generation\n  for generation in range(num_generations):\n      fitness_scores = np.array([evaluate_fitness(chrom) for chrom in population])\n      best_chromosome = population[np.argmax(fitness_scores)]\n      print(\"new fitness scores:\", fitness_scores)\n      print(f\"best chromosome in generation {generation} is {best_chromosome} with accuracy {fitness_scores[np.argmax(fitness_scores)]}\")\n      accuracy_per_generation.append(fitness_scores[np.argmax(fitness_scores)])\n      parents = elitism_and_selection(population, fitness_scores, 4, POPN_SIZE)\n      # parents = select_parents(population, fitness_scores, POPN_SIZE)\n      new_population = []\n      for i in range(0, POPN_SIZE, 2):\n          parent1, parent2 = parents[i], parents[i + 1]\n          child1, child2 = crossover(parent1, parent2)\n          # child1 = mutate(child1)\n          # child2 = mutate(child2)\n          new_population.extend([child1, child2])\n      population = np.array(new_population)\n  generations = list(range(1, len(accuracy_per_generation) + 1))\n\n\n  return best_chromosome","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:19:30.764184Z","iopub.execute_input":"2024-10-16T15:19:30.764581Z","iopub.status.idle":"2024-10-16T15:19:30.773576Z","shell.execute_reply.started":"2024-10-16T15:19:30.764543Z","shell.execute_reply":"2024-10-16T15:19:30.772631Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"genetic_algorithm(2, SPARSITY_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-10-16T15:22:43.452654Z","iopub.execute_input":"2024-10-16T15:22:43.453567Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"260a13fb2863475aa12930f7ab0fffcf"}},"metadata":{}},{"name":"stdout","text":"Pruning heads in model\n","output_type":"stream"},{"name":"stderr","text":" 10%|▉         | 54/564 [02:30<23:30,  2.77s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 12%|█▏        | 68/564 [03:09<23:05,  2.79s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 12%|█▏        | 69/564 [03:11<22:54,  2.78s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 13%|█▎        | 71/564 [03:17<22:47,  2.77s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 13%|█▎        | 73/564 [03:23<22:38,  2.77s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 13%|█▎        | 75/564 [03:28<22:55,  2.81s/it]Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7b74bb513e50>>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \n 13%|█▎        | 76/564 [03:31<22:45,  2.80s/it]","output_type":"stream"}]}]}